{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this analysis, we are going to dive into data from Hacker News, the popular tech and startup-oriented news user posting site. The dataset we will be using can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). Specifically, we are going to compare two types of posts whose title begins with the following:\n",
    "\n",
    "1. `Ask HN` = posts that are asked to the Hacker News community to answer a specific question.\n",
    "\n",
    "2. `Show HN` = posts that show the Hacker News community a project, product, or just generally something interesting. \n",
    "\n",
    "We'll compare these types of posts to determine the following:\n",
    "- Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "open_file = open('hacker_news.csv')\n",
    "read_file = reader(open_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a quick exploration of the first 5 rows, we will extract the first row which contains the headers, and add that to it's own variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers) \n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we've removed headers from `hn`, We're ready to filter our data. Since we are only concerned with posts that begin with \"Ask HN\" or \"Show HN\", we will create new lists of lists that contain just the data for those titles.\n",
    "\n",
    "To find those specific posts, we will use the string method, `startswith`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of ask_posts: 1744\n",
      "# of show_posts: 1162\n",
      "# of other_posts: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('# of ask_posts:', len(ask_posts))\n",
    "print('# of show_posts:', len(show_posts))\n",
    "print('# of other_posts:', len(other_posts))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, the first thing I want to know is whether ask_posts or show_posts receive more comments on average, so I will determine that next. \n",
    "\n",
    "It looks like the field, \"num_comments\", at index 4 is what we will want to use to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of Comments per Ask Post: 14.038417431192661\n",
      "Average # of Comments per Show Post: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    " \n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(\"Average # of Comments per Ask Post:\", avg_ask_comments)\n",
    "\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(\"Average # of Comments per Show Post:\", avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINDING #1: Based on these results, it appears that ask posts receive more comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we understand that ask posts receive more comments on average, then next thing we want to determine is if ask posts created at a certain time are more likely to attract comments. To do so, we will:\n",
    "1. Calculate the amount of ask posts created in each hour of the day, as well as the amount of comments received per hour.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize the `datetime` module to work with the data in the 'created_at' field, which is located at index 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'17': 100, '05': 46, '08': 48, '09': 45, '15': 116, '00': 55, '23': 68, '18': 109, '11': 58, '12': 73, '07': 34, '19': 110, '22': 71, '01': 60, '10': 59, '14': 107, '20': 80, '13': 85, '02': 58, '21': 109, '06': 44, '04': 47, '03': 54, '16': 108}\n",
      "{'17': 1146, '05': 464, '08': 492, '09': 251, '15': 4477, '00': 447, '23': 543, '18': 1439, '11': 641, '12': 687, '07': 267, '19': 1188, '22': 479, '01': 683, '10': 793, '14': 1416, '20': 1722, '13': 1253, '02': 1381, '21': 1745, '06': 397, '04': 337, '03': 421, '16': 1814}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for post in ask_posts:\n",
    "    dt_count_list = [post[6]] + [int(post[4])] # Combine lists through addition\n",
    "    result_list.append(dt_count_list)       \n",
    "    \n",
    "for row in result_list:\n",
    "    hour = row[0]\n",
    "    comment = row[1]\n",
    "    date_hour = dt.datetime.strptime(hour, \"%m/%d/%Y %H:%M\")\n",
    "    hour_only = date_hour.strftime(\"%H\")\n",
    "    \n",
    "    if hour_only not in counts_by_hour:\n",
    "        counts_by_hour[hour_only] = 1\n",
    "        comments_by_hour[hour_only] = comment\n",
    "    else:\n",
    "        counts_by_hour[hour_only] += 1\n",
    "        comments_by_hour[hour_only] += comment\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our `counts_by_hour` and `comments_by_hour` dictionaries, we will use these dictionaries to calculate the average number of comments ask posts created at each hour received.\n",
    "\n",
    "I will create a new list of lists to capture the avg comment results associated with each hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['17', 11.46], ['05', 10.08695652173913], ['08', 10.25], ['09', 5.5777777777777775], ['15', 38.5948275862069], ['00', 8.127272727272727], ['23', 7.985294117647059], ['18', 13.20183486238532], ['11', 11.051724137931034], ['12', 9.41095890410959], ['07', 7.852941176470588], ['19', 10.8], ['22', 6.746478873239437], ['01', 11.383333333333333], ['10', 13.440677966101696], ['14', 13.233644859813085], ['20', 21.525], ['13', 14.741176470588234], ['02', 23.810344827586206], ['21', 16.009174311926607], ['06', 9.022727272727273], ['04', 7.170212765957447], ['03', 7.796296296296297], ['16', 16.796296296296298]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Great! We now have the results we need. However, the formatting above makes it hard to easily identify the hours with the highest avg comment values.\n",
    "\n",
    "To make this more clear, we will finish by sorting the list of lists and then printing the five highest values in format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.46, '17'], [10.08695652173913, '05'], [10.25, '08'], [5.5777777777777775, '09'], [38.5948275862069, '15'], [8.127272727272727, '00'], [7.985294117647059, '23'], [13.20183486238532, '18'], [11.051724137931034, '11'], [9.41095890410959, '12'], [7.852941176470588, '07'], [10.8, '19'], [6.746478873239437, '22'], [11.383333333333333, '01'], [13.440677966101696, '10'], [13.233644859813085, '14'], [21.525, '20'], [14.741176470588234, '13'], [23.810344827586206, '02'], [16.009174311926607, '21'], [9.022727272727273, '06'], [7.170212765957447, '04'], [7.796296296296297, '03'], [16.796296296296298, '16']]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a list that equals avg_by_hour with swapped columns\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: use the sorted() function to sort the swap_avg_by_hour list\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "15:00:00: 38.59 average comments per post\n",
      "02:00:00: 23.81 average comments per post\n",
      "20:00:00: 21.52 average comments per post\n",
      "16:00:00: 16.80 average comments per post\n",
      "21:00:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Step 3: display sorted results in clean format\n",
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "for row in sorted_swap[0:5]:\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour_str = hour.time()\n",
    "    print('{hour}: {comment:.2f} average comments per post'.format(hour=hour_str, comment=row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [documentation for the data set](https://www.kaggle.com/hacker-news/hacker-news-posts), the times listed in this dataset are already in Eastern Standard Time (EST), which is the same time zone that I am in. That being the case, I do not have to convert the time zone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding #2: Ask posts created at 3pm EST get the highest amount of comments on average, suggesting that this is the optimal time to post a question if you are interested in getting as much feedback as possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
